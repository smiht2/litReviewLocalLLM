{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install sentence-transformers\n",
    "# ! conda install conda-forge openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile litRAGOllama.py\n",
    "import os\n",
    "# from PyPDF2 import PdfReader\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS as faiss\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from langchain.embeddings.base import Embeddings  # Correctly importing Embeddings\n",
    "# from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a litRAGOllama.py\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        return text_splitter.split_documents(documents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a litRAGOllama.py\n",
    "# Initialize the local embedding model\n",
    "local_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define a LangChain-compatible embedding wrapper\n",
    "class LocalEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embed a list of documents.\"\"\"\n",
    "        return [local_embedding_model.encode(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embed a single query.\"\"\"\n",
    "        return local_embedding_model.encode(text)\n",
    "\n",
    "\n",
    "# Function: Build FAISS index using LangChain's abstraction\n",
    "def build_faiss_index(documents):\n",
    "    try:\n",
    "        # Extract text from the documents\n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        \n",
    "        # Use LangChain's FAISS with local embeddings\n",
    "        embeddings = LocalEmbeddings()\n",
    "        vector_store = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        print(f\"Error building FAISS index: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a litRAGOllama.py\n",
    "# Function: Process a single PDF\n",
    "def process_pdf(pdf_path, retriever, llm, contribution_template, dataset_template):\n",
    "    try:\n",
    "        print(f\"Processing {os.path.basename(pdf_path)}...\")\n",
    "        pdf_title = os.path.basename(pdf_path)\n",
    "\n",
    "        # Prepare questions\n",
    "        contribution_qa = RetrievalQA.from_chain_type(\n",
    "            retriever=retriever,\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            chain_type_kwargs={\"prompt\": contribution_template}\n",
    "        )\n",
    "        dataset_qa = RetrievalQA.from_chain_type(\n",
    "            retriever=retriever,\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            chain_type_kwargs={\"prompt\": dataset_template}\n",
    "        )\n",
    "\n",
    "        # Ask questions\n",
    "        contribution = contribution_qa.run(\"What is the contribution of this paper?\")\n",
    "        dataset = dataset_qa.run(\"What dataset was used for the experiment?\")\n",
    "\n",
    "        return {\n",
    "            \"Title of the Paper\": pdf_title,\n",
    "            \"Contribution of the Paper\": contribution,\n",
    "            \"Dataset Used\": dataset\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF {pdf_path}: {e}\")\n",
    "        return {\n",
    "            \"Title of the Paper\": os.path.basename(pdf_path),\n",
    "            \"Contribution of the Paper\": \"Error\",\n",
    "            \"Dataset Used\": \"Error\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a litRAGOllama.py\n",
    "# Main Function: Process multiple PDFs\n",
    "def process_pdfs(input_folder, output_file):\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        # Initialize LLM (Ollama's Llama 3.3 model)\n",
    "        llm = ChatOllama(model=\"llama3.2\")\n",
    "        contribution_template = PromptTemplate(input_variables=[\"context\"], template=\"Context: {context}\\n\\nWhat is the contribution of this paper?\")\n",
    "        dataset_template = PromptTemplate(input_variables=[\"context\"], template=\"Context: {context}\\n\\nWhat dataset was used for the experiment?\")\n",
    "\n",
    "        # Iterate over all PDFs\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(input_folder, filename)\n",
    "\n",
    "                # Extract text and build FAISS index\n",
    "                documents = extract_text_from_pdf(pdf_path)\n",
    "                if not documents:\n",
    "                    results.append({\n",
    "                        \"Title of the Paper\": filename,\n",
    "                        \"Contribution of the Paper\": \"Error extracting text\",\n",
    "                        \"Dataset Used\": \"Error extracting text\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                vector_store = build_faiss_index(documents)\n",
    "                if vector_store is None:\n",
    "                    results.append({\n",
    "                        \"Title of the Paper\": filename,\n",
    "                        \"Contribution of the Paper\": \"Error building index\",\n",
    "                        \"Dataset Used\": \"Error building index\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                retriever = vector_store.as_retriever()\n",
    "\n",
    "                # Process each PDF and get results\n",
    "                result = process_pdf(pdf_path, retriever, llm, contribution_template, dataset_template)\n",
    "                results.append(result)\n",
    "                break\n",
    "\n",
    "        # Save results to Excel or CSV\n",
    "        df = pd.DataFrame(results)\n",
    "        if output_file.endswith(\".csv\"):\n",
    "            df.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            df.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error during processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a litRAGOllama.py\n",
    "input_folder = \"./../../\"  # Folder containing PDFs\n",
    "output_file = \"research_paper_analysis.csv\"  # Output Excel file\n",
    "# print(input_folder)\n",
    "\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"Input folder '{input_folder}' does not exist.\")\n",
    "else:\n",
    "    process_pdfs(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nbconvert\n",
    "# !pip install jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litRAGenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
